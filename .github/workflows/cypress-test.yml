name: Pre merge cypress tests

on:
  pull_request:
    paths:
      - 'cypress/e2e/**'
      - 'cypress/support/**'

jobs:
  run-tests:
    name: Run Cypress Tests
    permissions:
      contents: read
      pull-requests: write
    runs-on: ubuntu-latest
    steps:
      - name: Clone repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 1

      - name: Use Node.js 18.x
        uses: actions/setup-node@v3
        with:
          node-version: 18.x

      - name: Install dependencies
        run: npm install

      - name: Run Cypress tests
        run: npm run test-ui-headless

      - name: Upload Cypress test report
        uses: actions/upload-artifact@v3
        with:
          name: cypress-report
          path: |
            cypress/reports/merged-report.html
            cypress/reports/assets/

      - name: Discover report files
        id: discover-report
        run: |
          REPORT_FILES=$(find cypress/reports -type f -name 'merged-report.json')
          echo "REPORT_FILES=${REPORT_FILES}" >> $GITHUB_ENV

      - name: Extract test data from JSON files
        id: extract-test-data
        run: |
          echo "| **Test Type** | **Total** | **Passed** | **Failed** |" > test-report-summary.md
          echo "|--------------|-----------|------------|------------|" >> test-report-summary.md

          # Initialize counters
          api_total=0
          api_pass=0
          api_fail=0
          ui_total=0
          ui_pass=0
          ui_fail=0

          # Debugging: Verify report files
          echo "REPORT_FILES=${REPORT_FILES}"

          for report_file in ${REPORT_FILES}; do
            if [ -f "$report_file" ]; then
              echo "Processing file: $report_file"
              
              # Loop through results array
              jq -c '.results[]' "$report_file" | while read -r feature; do
                file=$(echo "$feature" | jq -r '.file')

                # Initialize per-feature counters
                feature_total=0
                feature_passed=0
                feature_failed=0

                # Loop through suites in each feature
                echo "$feature" | jq -c '.suites[]' | while read -r suite; do
                  suite_total=$(echo "$suite" | jq '.tests | length')
                  suite_passed=$(echo "$suite" | jq '[.tests[] | select(.pass == true)] | length')
                  suite_failed=$(echo "$suite" | jq '[.tests[] | select(.fail == true)] | length')

                  # Add suite results to feature-level counters
                  feature_total=$((feature_total + suite_total))
                  feature_passed=$((feature_passed + suite_passed))
                  feature_failed=$((feature_failed + suite_failed))
                done

                # Update global counters based on test type
                if [[ "$file" == *"apiTests"* ]]; then
                  api_total=$((api_total + feature_total))
                  api_pass=$((api_pass + feature_passed))
                  api_fail=$((api_fail + feature_failed))
                elif [[ "$file" == *"uiTests"* ]]; then
                  ui_total=$((ui_total + feature_total))
                  ui_pass=$((ui_pass + feature_passed))
                  ui_fail=$((ui_fail + feature_failed))
                fi
              done
            fi
          done

          # Debugging: Print calculated values
          echo "API Tests - Total: $api_total, Passed: $api_pass, Failed: $api_fail"
          echo "UI Tests - Total: $ui_total, Passed: $ui_pass, Failed: $ui_fail"

          # Append results to the Markdown file
          echo "| API Tests    | $api_total      | $api_pass  | $api_fail  |" >> test-report-summary.md
          echo "| UI Tests     | $ui_total       | $ui_pass   | $ui_fail   |" >> test-report-summary.md

      - name: Comment on PR with test report summary
        if: always()
        uses: marocchino/sticky-pull-request-comment@v2
        with:
          path: test-report-summary.md
          recreate: true

      - name: Make build pass or fail based on test results
        if: env.build_failed == 'true'
        run: |
          echo "Some tests failed. Failing the build."
          exit 1
